# AudioTrack

创建 AudioTrack 在 Android 8 之后有了 Builder 类。

```Java
public AudioTrack(
    AudioAttributes attributes,
    AudioFormat format,
    int bufferSizeInBytes,
    int mode,
    int sessionId
)

// Android O 开始
new AudioTrack.Builder()
        .setAudioAttributes(@NonNull AudioAttributes attributes)
        .setAudioFormat(@NonNull AudioFormat format)
        .setBufferSizeInBytes(@IntRange(from = 0) int bufferSizeInBytes)
        .setPerformanceMode(AudioTrack.PERFORMANCE_MODE_LOW_LATENCY)
        .setTransferMode(AudioTrack.MODE_STREAM)
        .setSessionId(AudioManager.AUDIO_SESSION_ID_GENERATE)  // 默认生成 ID
        .build();

// setPerformanceMode 性能模式有三种
public static final int PERFORMANCE_MODE_NONE;         // 系统默认
public static final int PERFORMANCE_MODE_LOW_LATENCY;  // 低延迟
public static final int PERFORMANCE_MODE_POWER_SAVING; // 省电模式

// setTransferMode 缓冲区传输模式有两种
public static final int MODE_STATIC = 0; // 播放之前传输，用于仅有一次数据？
public static final int MODE_STREAM = 1; // 边传边播放
```

AudioAttributes 用来封装描述音频流信息的属性集合。它取代了流类型来定义音频播放的行为的概念(例如 AudioManager#STREAM_MUSIC 或 AudioManager#STREAM_ALARM)。

AudioAttributes 允许应用程序通过允许应用程序定义以下方式指定更多信息：

- usage: Way 为什么需要播放声音？用处是什么。
- content：What 内容是什么。
- how: 播放的影响有什么，例如是否允许系统录音。（设置可选）

AudioAttributes 也提供了 Builder 类来创建。
```Java
new AudioAttributes.Builder()
        .setUsage(@AttributeSdkUsage int usage) // 应用场景
        .setContentType(@AttributeContentType int contentType) // 内容
        .setAllowedCapturePolicy(@CapturePolicy int capturePolicy); // 录音策略


// setUsage
AudioAttributes {
    public final static int USAGE_UNKNOWN;
    public final static int USAGE_MEDIA;                          // 多媒体
    public final static int USAGE_VOICE_COMMUNICATION;            // 语音通话
    public final static int USAGE_VOICE_COMMUNICATION_SIGNALLING; // 通话中的提醒，例如对方忙的提示音。
    public final static int USAGE_ALARM;                          // 有价值的提醒，例如闹铃
    public final static int USAGE_NOTIFICATION;                   // 通知铃声
    public final static int USAGE_NOTIFICATION_RINGTONE;          // 电话铃声
    public final static int USAGE_NOTIFICATION_COMMUNICATION_REQUEST; // 请求开始/结束通话的声音
    public final static int USAGE_NOTIFICATION_COMMUNICATION_INSTANT; // 即时通信的提示音，例如聊天
    public final static int USAGE_NOTIFICATION_COMMUNICATION_DELAYED; // 非即时通信的提示，例如邮件
    public final static int USAGE_NOTIFICATION_EVENT;             // 用户提醒
    public final static int USAGE_ASSISTANCE_ACCESSIBILITY;       // 可访问性，例如屏幕阅读
    public final static int USAGE_ASSISTANCE_NAVIGATION_GUIDANCE; // 用于导航指示音
    public final static int USAGE_ASSISTANCE_SONIFICATION;        // 界面操作音
    public final static int USAGE_GAME;                           // 游戏
    public final static int USAGE_ASSISTANT;                      // 语音查询、指令、帮助的回应
}

// setContentType
AudioAttributes {
    public final static int CONTENT_TYPE_UNKNOWN:      // 未知
    public final static int CONTENT_TYPE_MOVIE:        // 电影
    public final static int CONTENT_TYPE_MUSIC:        // 音乐
    public final static int CONTENT_TYPE_SONIFICATION: // 超声
    public final static int CONTENT_TYPE_SPEECH:       // 语音
}
```
音频格式 Format
```Java
// AudioFormat 的构建
new AudioFormat.Builder()
        .setEncoding(AudioFormat.ENCODING_PCM_16BIT) // 采样位深
        .setSampleRate(sampleRateInHz) // 采样率
        .setChannelMask(channelConfig) // 通道量宏定义
        .build()

// 通道不是数量，而是对应场景的单声道和立体式两个常量。大于 1 的声道都采用立体声。
public static final int CHANNEL_OUT_MONO;   // 单声道
public static final int CHANNEL_OUT_STEREO; // 立体声。
```

BufferSize 用于缓存要播放音频数据。根据采样位深、采样率和通道数计算大小，然后成一个大于 1 的系数，一般是 1.5 或者 2，换算成字节数。
```Java
//                            位深的字节       *    采样率   * 通道数    *   倍数
int bufferSizeInBytes = (BITS_PER_SAMPLE / 8) * sampleRate * channels * bufferSizeFactor;
// 有一个函数来专门计算 AudioTrack 需要最小缓存大小
final int minBufferSizeInBytes = (int) (AudioTrack.getMinBufferSize(
    sampleRate, channelConfig, AudioFormat.ENCODING_PCM_16BIT) * bufferSizeFactor);
```






```Java
  // Creates and AudioTrack instance using AudioAttributes and AudioFormat as input.
  // It allows certain platforms or routing policies to use this information for more
  // refined volume or routing decisions.
  private static AudioTrack createAudioTrackBeforeOreo(int sampleRateInHz, int channelConfig,
      int bufferSizeInBytes, @Nullable AudioAttributes overrideAttributes) {

    // Create an audio track where the audio usage is for VoIP and the content type is speech.
    return new AudioTrack(getAudioAttributes(overrideAttributes),
        new AudioFormat.Builder()
            .setEncoding(AudioFormat.ENCODING_PCM_16BIT)
            .setSampleRate(sampleRateInHz)
            .setChannelMask(channelConfig)
            .build(),
        bufferSizeInBytes, AudioTrack.MODE_STREAM, AudioManager.AUDIO_SESSION_ID_GENERATE);
  }

  // Creates and AudioTrack instance using AudioAttributes and AudioFormat as input.
  // Use the low-latency mode to improve audio latency. Note that the low-latency mode may
  // prevent effects (such as AEC) from working. Assuming AEC is working, the delay changes
  // that happen in low-latency mode during the call will cause the AEC to perform worse.
  // The behavior of the low-latency mode may be device dependent, use at your own risk.
  @TargetApi(Build.VERSION_CODES.O)
  private static AudioTrack createAudioTrackOnOreoOrHigher(int sampleRateInHz, int channelConfig,
      int bufferSizeInBytes, @Nullable AudioAttributes overrideAttributes) {

    // Create an audio track where the audio usage is for VoIP and the content type is speech.
    return new AudioTrack.Builder()
        .setAudioAttributes(getAudioAttributes(overrideAttributes))
        .setAudioFormat(new AudioFormat.Builder()
                            .setEncoding(AudioFormat.ENCODING_PCM_16BIT)
                            .setSampleRate(sampleRateInHz)
                            .setChannelMask(channelConfig)
                            .build())
        .setBufferSizeInBytes(bufferSizeInBytes)
        .setPerformanceMode(AudioTrack.PERFORMANCE_MODE_LOW_LATENCY)
        .setTransferMode(AudioTrack.MODE_STREAM)
        .setSessionId(AudioManager.AUDIO_SESSION_ID_GENERATE)
        .build();
  }
```

## 启动/关闭

通过 `play()` 开始播放，`stop()` 关闭播放。

## 加载数据

AudioTrack 需要一个单独的线程来独立不停的传输数据.

```Java
    @Override
    public void run() {
      Process.setThreadPriority(Process.THREAD_PRIORITY_URGENT_AUDIO);

      // Fixed size in bytes of each 10ms block of audio data that we ask for
      // using callbacks to the native WebRTC client.
      final int sizeInBytes = byteBuffer.capacity();

      while (keepAlive) {
        // Get 10ms of PCM data from the native WebRTC client. Audio data is
        // written into the common ByteBuffer using the address that was
        // cached at construction.
        getPlayoutData(byteBuffer, sizeInBytes);
        // Write data until all data has been written to the audio sink.
        // Upon return, the buffer position will have been advanced to reflect
        // the amount of data that was successfully written to the AudioTrack.
        assertTrue(sizeInBytes <= byteBuffer.remaining());

        int bytesWritten = audioTrack.write(byteBuffer, sizeInBytes, AudioTrack.WRITE_BLOCKING);
        if (bytesWritten != sizeInBytes) {
          // If a write() returns a negative value, an error has occurred.
          // Stop playing and report an error in this case.
          if (bytesWritten < 0) {
            keepAlive = false;
          }
        }
        if (useLowLatency) {
          bufferManager.maybeAdjustBufferSize(audioTrack);
        }
        // The byte buffer must be rewinded since byteBuffer.position() is
        // increased at each call to AudioTrack.write(). If we don't do this,
        // next call to AudioTrack.write() will fail.
        byteBuffer.rewind();
      }
    }
```

一般在启动 AudioTrack 之后启动线程，在 AudioTrack 关闭之前就将线程关闭。