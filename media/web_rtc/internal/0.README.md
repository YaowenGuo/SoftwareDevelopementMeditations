# WebRTC 架构

WebRTC 的架构官方给出了一个简单的图，然而对于读代码来说远远不够，还需要更详细的一些。能够了解架构能帮助阅读代码时理解代码，这比通过代码推测其结构和目的要简单的多。

另外，在阅读代码时，**知道代码为什么这样写远比知道怎么写的要好。知道怎么写的也只是简单知道是怎么实现的，而知道为什么这样写就能知道可不可以不这样写，才能修改代码。**

> 首先回顾一下粗略的 API 流程

1. 创建 PeerConnectionFactory

2. 创建 PC

3. 设置 MediaSource 和 Track
    1. 创建 Media Source
    2. AddTrack

4. 媒体协商（SDP 格式的 Offer 和 Answer）
    1. 创建 Offer, SetLocalDescription.
    2. 接收 Offer, SetRemoteDescription.
    3. 创建 Answer, SetLocalDescription.
    4. 接收 Answer, SetRemoteDesctiption.

5. 尝试最优的网络连接（ICE 交换，可以进行多次。接收端和发送端都有此流程。）
    1. 接收到 ICE 创建成功的回调后发送给远端。
    2. 接收到 ICE 后，设置给本地。
6. 实际建立 P2P 数据传输

为了建立连接，WebRTC 需要先进行会话协商，才能建立实际连接传输数据。这样 WebRTC 连接的流程可以分为会话协商和 P2P 数据连接两部分。

1. 会话协商
2. P2P 数据传输

会话协商又可以分为 `① 媒体协商` 和 `② ICE` 两个过程，两者其实是为 P2P 连接准备不同的部分。媒体协商确定媒体数量和类型。ICE 为 P2P 准备网络信息。（但是并不是媒体协商结束后 ice 才开始，而是协商开始后，ICE 就开始收集网络信息了）

```
+----------------------------+
| 会话协商      |     P2P 连接 |
+----------------------------+
| 媒体协商  <------>   媒体类   |
|   ICE   <------->   网络    |
+----------------------------+
```

## 映射关系

为了将`协商`和`数据传输`隔离，职责更加清晰。WebRTC 其实有两套类来分管不同的部分。因为协商就是为建立数据传输做准备的，两个部分中的有着一对一的映射关系。

### PC <---> Call

首先需要明确的点是：WebRTC 可以同时同多个人建立 P2P 连接，连接的双方被称为对等端。WebRTC 将建立的对等连接称为 PC(PeerConnection)，代表一个对等端的连接。而在内部，实际进行数据传输的连接抽象为一个 Call。


### RtpTranceiver <---> Channel

对于一个数据收发流，也即一个 m= 块，WebRTC 会话中对外的抽象是 RtpTranceiver。RtpTransceiver 代表的是媒体协商的一个收发器。收发器既能发送，又能接收。对于 Unified Plan，一个 RtcTranscervier 仅有一个 sender 和一个 receiver。 为了兼容 Plan B，可以添加多个 Sender 和 receiver，并通过 a=ssrc 关联。

RtcTranscervier 是会话协商中的类，在 P2P 中对应一个 Channel (数据通道 实现类是 VoiceChannel/VideoChannel，基类是 BaseChannel)，用于实际的数据传输。Channel 是一个数据传输的抽象，每个对等端连接都可以包含多个 Channel。WebRTC 的 Channel 是一种双向流，在 Unified Plan 规范中，一个 Channel 包括一个发送的 Stream 和一个接收的 Stream。为了兼容 Plan B，一个 Channel 可以包含多个接收和发送 Stream。


### Sender/Receiver <---> Stream

如上所述，媒体协商中的 sender 和一个 receiver 也对应这 P2P 传输的 SendStream 和 RecvStream.


## 架构设计的好处

WebRTC 的流程由 JSEP 协议定义（rfc8829）。从 WebRTC 发展历程来讲，由于先有 Google 版的 WebRTC 实现，后推进的 RFC 标准化，为了实现 RFC 规定的 API， Google 的 WebRTC 实现两套独立的对象，用于会话协商的 API 和内部链接的 API，是一套为了应对标准同时逐渐演化的产物。

从另一方面说，这样的架构也更加灵活，能够应对变化，在内部快速的迭代，而保持 API 不变。


## MediaEngine

WebRTC 的多媒体需要访问硬件。WebRTC 能够`同时`与多个对等端建立连接，但是硬件设备是`唯一`的，需要在多个 PC 之间共享。为了能够在多个 PC 之间管理硬件，WebRTC 在每台设备上只能创建个**唯一的** MediaEngine 用于管理媒体设备(实现类是 CompositeMediaEngine)。音频设备处理和视频处理是完全不同的，CompositeMediaEngine 是一个聚合类，包含**一个** WebRtcVoiceEngine 和 **一个** WebRtcVideoEngine(如果不支持 Video 会创建也给 NullWebRtcVideoEngine)

> 跟 Voice 相关的设备唯一的都组织在 WebRtcVoiceEngine 中，包括：

- 一个硬件层接口 ADM(AudioDeviceModule)
- 一个 Audio 3A 处理的对象 APM (AudioProcessing AudioProcessingModule)
- 一个 AudioMixer，用于混音算法。
- 一个 AudioEncoderFactory，用于获得该设备支持的编码类型，以及创建编码器。
- 一个 AudioDecoderFactory 用于获得设备支持的解码类型，以及创建解码器。
- 一个 AudioFrameProcessor，让用户可以附加一个自定义音频处理功能。


> 相比之下创建 VideoEngine 依赖简单很多：

- 一个 VideoEncoderFactory 用于获得设备支持的 Video 编码类型，并创建编码器。
- 一个 VideoDecoderFactory 用于获得设备支持的 Video 解码类型，并创建解码器。

### PCFactory

现在才引入 PCFactory(PeerConnectionFactory)的概念显得有些迟，但是却是最合适的时机。我们可以推论为什么需要一个 PCFactory，以及哪些内容需要在 PCFactory 中就准备。为了创建 PC 时保证上面提到的硬件相关的对象唯一，而且不需要开发者自己维护这些内容（整个流程过于复杂，事实上 API 的设计就是在尽力简化这些流程，不把复杂性留给用户）, WebRTC 抽象类 PCFactory 对象来管理以上提到的设备上唯一的对象。使用 PCFactory 来创建 PC, 同时在创建多个连接对象时自动将其传给 PC。

### MediaChannel & BaseChannel

在与多个对等端建立连接时，需要将用户采集的数据发送给多个人，WebRTC 的 Channel 负责这样的流程。为了将采集的 Voice 和 Video 发送到 Channel, WebRTC 抽象了 MediaChannel 的概念，每个 Channel 都唯一对应一个 `WebRtcVoiceMediaChannel` 或者 `WebRtcVideoChannel`。MediaChannel 和 BaseChannel 是一种桥接，BaseChannel 持有一个 MediaChannel。BaseChannel 是对媒体协商暴露的接口，MediaChannel 完成各种实际的媒体操作。同时 BaseChannel 也实现了 MediaChannel 的网络接口，用于发送 MediaChannel 流过来的数据。

```
                                        +--------------------------------------+
   MediaChannel.NetworkInterface        |              MediaChannel            |
                ^                       +~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~+
                |                       | network_interface_: NetworkInterface |
                |                       +--------------------------------------+
                |                                    /        \
+-----------------------------+      +-------------------+     +-------------------+
|       BaseChannnel          |      | VoiceMediaChannel |     | VideoMediaChannel |
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~+      +-------------------+     +-------------------+
| media_channel_:MediaChannel |                ^                          ^
+-----------------------------+                |                          |
            ^      ^                           |                          |
           /        \                          |                          |
+--------------+ +--------------+   +-------------------------+ +--------------------+
| VoiceChannel | | VideoChannel |   | WebRtcVoiceMediaChannel | | WebRtcVideoChannel |
+--------------+ +--------------+   +-------------------------+ +--------------------+
```

### AudioEngine

Audio 的流程都封装在 AudioEngine 中。这里包含了 Audio 发送到网络前的各种处理。

为了抽象硬件，WebRTC 抽象了一个 ADM (AudioDeviceModule) 类用于封装硬件，各个平台实现不同 API 封装。ADM 包含一个 Input 类型的 AudioRecord 和一个 Output 类型的 AudioTrack。

采集到的 Audio 数据需要经过一些处理，混音、3A 处理，这些都在分叉之前完成。这些基本会和硬件相关，因此对多有连接都一样，统一处理完再分叉。Audio 将其封装在一个 APM (AudioProcessingModule)中。

由于不同 PC 可能采用不同编解码，因此 Voice 在 `AudioTransportImpl` 中完成 3A 处理和混音操作后，复制数据分叉发送给 `ChannelSend` 完成编码，由 `ChannelReceive` 完成解码。

### 拥塞控制和网络

WebRTC 使用的 RTP 协议以及 UDP 协议本身不包括拥塞算法的内容。因此在 ChannelSend 后包括 RTP 封包（RTPSenderAudio）、（RTPSender）、

再往下，发送端拥塞控制算法（PacingController），拥塞控制需要统计网络的丢包评估网络数据，因此需要接收端反馈接收到的包（RtpStreamReceiverController）

拥塞控制之下的网络发/收使用同一个类，最终这些数据经过 MediaChannel 发送到 BaseChannel 中。


### ICE

控制 P2P 连接选择（P2PTransportChannel），实际建立的连接（Connection），以及底层的端口（UDP/TCP/STUN）

ICE 流程用于收集可用的网络，WebRTC 中将网络连接抽象为 Connection，在底层支持 UDP/TCP/STUN 连接，将其抽象为 Port，因此 ICE 过程就是收集网络信息，根据网络信息创建 Connction，并选择最优的连接，并通知上层开始发送数据。


## 总结

最终，我们可以得到一个数据流的视角的架构图：

```
+--------------------------------------------+   +----------------------------------------------------+
|               AudioEngine                  |   |                       VideoEngine                  |
+--------------------------------------------+   +--------+-------------------------------------------+
|                                            |   |Capture |       Capture       |        Render       |
+-------------+------↓-------+---------------+   +--------+-------------------------------------------+
|  Device     |   Recoder    |    Track      |   | Device |        Source       |         Sink        |
+-------------+------↓-------+---------------+   +--------+-------------------------------------------+
|    ADM      |     AudioDeviceBuffer        |   | Codec  | VideoStreamEncoder  |  VideoReceiveStream |
+-------------+------↓-------+---------------+   +--------+-------------------------------------------+
|3A+Mix+自定义 |       AudioTransportImpl     |   |        |VideoSendStreamImpl  | VideoReceiveStream2|
+-------------+------↓-------+---------------+   +--------+---------------------+---------------------+
|Send/Recv|AudioSendStream|AudioReceiveStream|   |        |    RtpVideoSender   |RtpVideoStreamReceiver2|
+-------------+--------------+---------------+   |        |                     |                    |
|Codec| NetEQ | ChannelSend  | ChannelReceive|   |        |                     |                    |
+-------------+--------------+---------------+   +--------+------------------------------------------+
                   ︽                                                         ︽
                   ︾                                                         ︾
+-------------+------------------------------+------------+------------------------------------------+
|    拥塞      | RTPSenderAudio/RTPSenderVideo| rtp 封解包  |               RtpDemuxer                 |
|    控制      |          RTPSender           | 发送接口    |         RtpStreamReceiverController      |
|    算法      |RtpPacketSender(TaskQueuePacedSender)|pacer，入队列|                                   |
|             |PacingController              |算法，发送回调|                                           |
|             | PacketRouter   |根据SSRC将包发送到正确的模块中|                                           |
|             |        RTPSenderEgress       |时间戳，重传记录|                                         |
+-------------+------------------------------+-----------+-------------------------------------------+
| Transport接口|     WebRtcVoiceMediaChannel              |              WebRtcVideoChannel           |
+-------------+--------------------------------------------------------------------------------------|
|             |                                       BaseChannel                                    |
+-------------+--------------------------------------------------------------------------------------+
|     RTP     |                                      RtpTransport                                    |
+-------------+--------------------------------------------------------------------------------------+
|     P2P     |                                  P2PTransportChannel                                 |
+-------------+--------------------------------------------------------------------------------------+
|  Connection |                                       Connection                                     |
+-------------+--------------------------------------------------------------------------------------+
|     Port    |                                      UDP/TCP/STUN                                    |
+-------------+--------------------------------------------------------------------------------------+
```

> 总结：

- 设备相关的对象（保证唯一）在连接之前就建立了。

- 媒体协商是为了确定传输的媒体种类和数量以及其它媒体相关参数。因此媒体协商过程创建 AudioTransportImpl 到 Connection 之上的对象。因为这些对象每个代表一个数据流。

- ICE 创建 Connection 和 Port，它们代表实际的连接，这时候网络已经知道了就可以建立连接了。同时为每个 MediaChannel 创建了一个 P2PTransportChannel，用于选择最优的网络。因此媒体协商的过程，就是确定 MediaChannle 以及其 Sender 和 Receiver 的过程和 P2PTransportChannel 的流程。


这里需要区分用于`协商`和用于`传输`的类，以及它们的映射关系。

```
     协商                                                `传输`
PeerConnection         <------->  Call
RtpSenderBase          <------->  ChannelSend / RtpVideoSender
Audio/VideoRtpReceiver <------->  ChannelReceive / RtpVideoStreamReceiver2
                                          ╭-- 一个 ->  voe::ChannelSend {ModuleRtpRtcpImpl2 {RTPSender}, RTPSenderAudio }
                                        ╭-- 一个 ->   webrtc::AudioSendStream
                                      ╭-- 多个 ->  WebRtcAudioSendStream 和 WebRtcAudioReceiveStream
                                 ╭- 一个 -> WebRtcVoiceMediaChannel / WebRtcVideoChannel
RtpTransceiver         <------>  BaseChannel(VoiceChannel/VideoChannel)
```
- 创建 PC 的时候内部创建 Call
- 添加媒体的时候创建 RtpTransceiver，然后用于生成 offer/answer
- 应用 offer/answer 的时候创建 Channel，BaseChannel(VoiceChannel/VideoChannel) 和 MediaChannel( WebRtcVoiceMediaChannel/WebRtcVideoChannel)
- ice 的时候创建 Connection.

**The cricket::Channel class adds no structuring benefits, and should be merged with RtpTransceiver.**

**The question was raised about whether cricket::MediaChannel had any reason to exist too - that too seems to be a two-way construct.**

**cricket::MediaChannel has interfaces to send and receive packets. It seems to beg to be integrated into the Transport.**
https://bugs.chromium.org/p/webrtc/issues/detail?id=13931&q=BaseChannel&can=2