# Audio Play

WebRtcVoiceEngine 中的 AudioState 调用了 AudiDeviceModule 的 `InitPlayout` 和 `StartPlayout` 函数后，就开始获取数据了。

WebRtcAudioTrack 中关于数据的播放流程

```
WebRtcAudioTrack.java::AudioTrackThread.run()
↓
WebRtcAudioTrack.nativeGetPlayoutData
↓
AudioTrackJni::GetPlayoutData
↓ audio_device_buffer_
AudioDeviceBuffer::RequestPlayoutData + AudioDeviceBuffer::GetPlayoutData
↓ audio_transport_cb_
AudioTransportImpl::NeedMorePlayData
|
| mixer_->Mix(nChannels, &mixed_frame_); 混音
| ProcessReverseAudioFrame(audio_processing_, &mixed_frame_); 附加音频处理
| mixer_
AudioMixerImpl::Mix()
↓
AudioMixerImpl::GetAudioFromSources
↓ source_and_status->audio_source
AudioReceiveStream::GetAudioFrameWithInfo
↓ channel_receiver_
ChannelReceive::GetAudioFrameWithInfo
↓ acm_receiver_
acm2::AcmReceiver::GetAudio
↓
NetEqImpl::GetAudio()
```