# 线程


### 线程模型

多线程的实现不止在系统内核中，也可以使用应用程序层实现，这种实现不是由系统调度的，而是通过软件的长跳转(longjump），称为用户线程。由于应用线程调度仅仅是一个跳转，不像内核线程需要保存寄存器等状态，用户线程往往更高效。由于不同的线程实现，就有了实际应用中三种不同线程模型。

#### 1:1

一个应用线程对应一个内核线程。这种实现方式用户线程并没有实现线程调度，线程仅仅是对内核线程的封装，以提供一个套简洁一致的 API。例如 Java 的线程就是对各个平台线程的封装。

缺点：线程调度由内核调度，性能不如其它模型高。

#### 1:N

一个内核线程对应 N 个用户线程。由应用程序完成线程的调度。这种实现通常在一些没有内核线程的系统上，应用层通过自己实现线程调度来实现并发。

缺点：无法实现高并发

#### M:N

这种线程也称为混合线程模型。N 个用户线程依附于 M 个内核线程。这种实现避免了比 1:1 线程更加高效，同时避免了 1:N 模型中无法实现抢占式调度。

缺点：实现过于复杂。
而且，一旦一个线程阻塞，将阻塞在同一个内核线程中的所有应用线程。

> 多线程实现的现状：

主流的系统都在转为 1:1 的线程模型。虽然 M:N 模型更高效，但是其实现过于复杂，在现代计算机越来越倾向于多核化，以及一些超标量流水线技术等支持，再加上 N:M 实现需要的复杂的代码消耗，M:N 实现带来性能提升并不与其付出成比例。过高的实现复杂度带来的性能回报并不高。

Linux 上 M:N 模型的 NGPT 实现，在 2003 年中期被放弃了，把这个领域完全留给了 NPTL。
有个说法没有验证：
FreeBSD从7.0开始转为 1:1 实现。
Solaris 之前实现了 M:N 线程模型，从某个版本也开始转移到 1:1 模型。

Java 也遗弃了 M:N 的线程模型。现在线程仅仅是对内核线程的一个封装。


我觉得 N:M 线程模型被抛弃的另一个原因是：线程的编程模型不适合应用级调度，或者说输给了协程。应用线程在编程 API 上不如协程，以为它不支持返回结果，不支持切换。内核专心实现内核线程，而将应用级的切换留给协程这种编程模型更好的技术，是比较优化的选择。

### 线程实现

对于目前常见的系统，由于线程的实现从根本上依赖于操作系统，其用户 API 都不过是对系统线程的一个包装而已。以 UNIX 为例 `POSIX` 标准的线程 API `Pthreads`。

```C
#include <pthread.h>
#include <stdio.h>

void *mythread(void *arg) {
  printf("Hello concurrency\n");
  return NULL;
}

int main() {
  pthread_t p1;
  pthread_create(&p1, NULL, mythread, "A");
  pthread_join(p1, NULL);
}
```

```Java
Thread thread = new Thread(() -> {
    System.out.println("child thread,");
});
thread.start();
```

其中 `Thread.start()` 的实现为

```Java
// java.lang.Thread
public synchronized void start() {
    ...
    try {
        start0();
        started = true;
    } finally {
       ...
    }
}
```
// 其 JDK 实现为
```
// https://github.com/openjdk/jdk/blob/739769c8fc4b496f08a92225a12d07414537b6c0/src/java.base/share/native/libjava/Thread.c

static JNINativeMethod methods[] = {
    {"start0",           "()V",        (void *)&JVM_StartThread},
    ...
};
```
安卓 4.4 开始引入 ART 虚拟机。

```C++
// https://android.googlesource.com/platform/art/+/master/openjdkjvm/OpenjdkJvm.cc
JNIEXPORT void JVM_StartThread(JNIEnv* env, jobject jthread, jlong stack_size, jboolean daemon) {
  art::Thread::CreateNativeThread(env, jthread, stack_size, daemon == JNI_TRUE);
}

// https://android.googlesource.com/platform/art/+/master/runtime/thread.cc

void Thread::CreateNativeThread(JNIEnv* env, jobject java_peer, size_t stack_size, bool is_daemon) {
  CHECK(java_peer != nullptr);
  ...
  Thread* child_thread = new Thread(is_daemon);
  ...
  if (child_jni_env_ext.get() != nullptr) {
    ...
    pthread_create_result = pthread_create(&new_pthread,
                                           &attr,
                                           Thread::CreateCallback,
                                           child_thread);
    ...
  }
  ...
}

```

## 线程撕裂者/超线程

两核四线程
一个 ALU 同一时刻只能执行一个程序。

一核里一般含有一套 ALU,一套寄存器。而超线程则是一个核里一套 ALU 和多套寄存器。随着计算机的发展，由于计算单元和内存的速度差距越来越大。在每个核里，提供多套寄存器和缓存，它们公用 ALU。ALU 通过轮询使用寄存器和缓存，在使用一套寄存器的时候，另一套寄存器加载数据。这样看起来就增加了核心数量，同时解约了硬件成本。这样一核就能计算多个线程。




## 线程本地存储

也就是线程的上下文，包括栈指针、程序计数器以及通用目的的寄存器。

https://blog.csdn.net/linyt/article/details/51931737
https://www.cnblogs.com/liu6666/p/12729014.html
https://blog.csdn.net/hujutaoseu/article/details/74936222



## 线程安全

在拥有共享数据的多条线程并行执行的程序中，线程安全的代码会通过同步机制保证各个线程都可以正常且正确的执行，不会出现数据污染等意外情况

> 问题产生的原因

1. 多个线程在同时操作共享的数据
2. 操作共享数据的代码有多条

当一个线程执行操作共享数据的多条代码时，由于线程切换是随机的，会导致执行过程中，数据被其他线程更改。这样使数据产生预期之外的值。

为了解决这个问题，需要线程同步，即对同一个数据的一块操作必须整体要么执行完，要么不执行。不能被其它线程打断。实现操作的原子性。

**多线程的共享数据的竞争有一个比喻，就像多个人去争抢几个桃子一样，结果难以预期。具体谁能抢到是无法推测的，这不满足程序的确定性**

### 临界区

### 数据竞争

当程序未正确同步时，就会存在数据竞争。java 内存模型规范对数据竞争的定义如下：

在一个线程中写一个变量，
在另一个线程读同一个变量，
而且写和读没有通过同步来排序。

如果一个多线程程序能正确同步，这个程序将是一个没有数据竞争的程序。

## 线程同步

即当有一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作（处于等待状态），直到该线程完成操作，其他线程才能对该内存地址进行操作。

“同”字从字面上容易理解为一起动作
其实不是，“同”字应是指协同、协助、互相配合。

- 好处：解决了线程安全的问题

- 弊端：降低了线程的执行效率，因为同步外的线程都会判断锁，所得获取和释放都需要额外的操作。

实现同步的前提是，要实现同步的所有线程使用同一个锁。

### 线程同步四种方式。
https://blog.csdn.net/qq_44836294/article/details/108638224

- 临界区（Critical Section）：可以使用临界区对象。拥有临界区的线程可以访问被保护起来的资源或代码段，其他线程若想访问，则被挂起，直到拥有临界区的线程放弃临界区为止。

- 事件（Event）：为协调共同对一个共享资源的单独访问而设计的。

- 互斥量（Mutex）：为控制一个具有有限数量用户资源而设计。
   使用 synchronized 或者 Lock 实现线程同步。

- 信号量（Semaphore）：用来通知线程有一些事件已发生，从而启动后继任务的开始。普遍用于生产者消费者问题，我可能会有多个资源多个线程都可以共享，生产者将信号量加1，消费者减1，比如减到小于0当前线程就被阻塞，当生产者再生产出一个资源，向那些阻塞的线程发出信号，让他们重新激活。



从并发性的介绍，我们看到了并发编程中的一个基本问题:我们希望以原子方式执行一系列指令，但由于单个处理器(或多个线程在多个处理器上并发执行)上存在中断，实际上无法实现。通过对临界区使用锁，从而确保任何这样的临界区都**表现的像**单个原子指令一样执行。

当释放锁时，如果有等待的线程(卡在lock()中)，其中一个将(最终)注意到(或被告知)锁状态的变化，获取锁，并进入临界区。

传统同步的特点就是对于单核单处理，多线程，尤其是单片机上面比较简单的处理器，一般处理器不需要提供原子操作，因为只要通过简单的开关中断操作即可对锁对象做原子性的修改操作。
对于多核多处理器环境下的数据同步，如果我要用开关中断来实现原子性是不切合实际的。

我们再看一下上面的这张图。如果我们要线程A和线程B在单核单处理器的情况下，那么只要加载的时候加一个锁，如果线程A先执行，这个锁在它访问时是开的，在要用这个资源之前就把这个锁关上，然后做加载、计算和存储，即便我当前在做加载完成了或者计算完成的时候，线程A被操作系统调度出去了，把线程B调度进来，B这边也会面对这把锁，当它要访问下面资源的时候就会被锁住，同时当前线程会被挂起，等到A执行的时候，最后存储结果完了以后，把锁打开，线程B就可以从这里继续执行下去。而多个处理器，就像我们刚才讲的，我这边线程A对线程B是没法进行任何干扰的，这两个线程是完全同时执行的，**delete 错误 所以这个时候你要用传统的锁是无法同步的，** ***在多核处理器环境下，锁的实现也需要基于原子操作***。

## 内存模型

C++ 11 内存模型是首个面向多线程的内存模型。在之前（C++98/C++03），虽然也能通过各个平台提供的库编写多线程代码，但是一致没有一个标准兼容各个平台。

C++11 被设计为运行在抽象的多线程机器上。它带有一个良好定义的内存模型：即定义了在访问内存时哪些是编译器做保证或者不保证的。

考虑以下示例，其中两个线程同时访问一对全局变量：
```
           Global
           int x, y;

Thread 1            Thread 2
x = 17;             cout << y << " ";
y = 37;             cout << x << endl;
```

在 C++98/C++03 下，这甚至不是未定义的行为; 问题本身是毫无意义的，因为标准不考虑任何称为“线程”的任何东西。

在 C++11 下，结果是未定义的行为，因为通常加载和和存储没有被定义为原子的。看起来似乎并没有什么改善...... 是的，其本身并没有。

但是在 C++11 中你可以这样写：

```
           Global
           atomic<int> x, y;

Thread 1                 Thread 2
x.store(17);             cout << y.load() << " ";
y.store(37);             cout << x.load() << endl;
```


### 什么是内存模型？

- 用于描述线程如何与内存及共享数据交互的细节和抽象。
- 多线程程序要求编程语言指定内存模型
    - 由于缓存的存在，多核处理器中，在任何时刻运行中的线程看到内存中的共享数据可能是不同的值
    - 没有内存模型，三方线程库、编译器以及硬件在编译器优化和硬件优化中存在这不一致和矛盾
    - 源代码能够在被编译器、CPU 和内存重排序
    - 模型必须定义何种重排序是允许的
    - 提供关于何时访问内存的最小保证
    - 定义何时多个线程可以访问同一内存
    - 指定一个线程的赋值何时可以对并发执行的另一线程可见
    - C++98/C++03 仅定义了单线程程序，并没有定义内存模型。


对于单线程程序，内存模型并没有带来任何裨益。但是对于多线程程序，必须遵循访问共享内存的协议，否则结果无法预测。如今，无论 PC 还是移动处理器，多核处理器都很常见，这意味着两个线程在同一时刻读取共享数据可能获得不同的值。**要求所有的线程始终保持同步非常高昂的性能损失。**当你编写多线程程序时，你将决定何时内存不一致是可以接受的，何时无法接受。内存模型的一个目的是给开发人员一种必要时编写保证共享数据同步代码的方式。

当讨论内存模型时，我们需要区分三个不同部分。
- 开发者编写的代码
- 编译器生成的用于硬件执行的指令
- CPU 执行指令时的内存操作

当我们编写程序时，语句具有严格的顺序。是具体问题的解法。当编译器编译时，为了提高性能，指令被重排序。编译结果期望能保持一致。同样，处理器和内存总线会对内存访问进行重排序以提高性能。甚至可能将一些小的写入操作做一个整体操作。内存模型扮演的角色是，限制这些重排序，以让开发者能够推测多线程程序可能的行为。模型必须定义何时多线程访问相同位置的内存是合法的。也必须定义当一个线程更改了内存如何对另一线程可见。


### 为什么正确的模式如此重要?

- Java
    - 内存模型大约在 1995 年出现
    - 首个提供内存模型的广泛使用的语言
    - 内存模型的动机是保证类型安全和提供安全保证。
    - Java 被设计为在沙盒环境中执行不可信代码和可信代码。

- pthreads
    - 约 1995 年左右开发出来
    - pthread 实现在发生数据竞争是导致 UB.
    - 并没有定义内存模型。

- First idea for a C++ memory model is to use Java Model
    - 他们决定不采用这个方向，Java 的目标与 c++ 语言不符。

    - Java 模型要求对一些类型的读取必须是原子类型
    - Java 必须确保指针不会指向另一个不同类型的对象并加载数据。
    - 在 C++ 做出 java 中的保证消耗高昂。

- C++ 工作组发现在不限制编译器的情况下，一个库根本无法实现线程安全。

    - 这就是为什么除非还定义了一个新的内存模型，添加线程库没有什么价值
    - 他们可以为 C++ 添加内存模型，并允许第三方实现线程库
    - C++ 工作局决定为 C++ 同时添加内存模型和线程

- C++ 内存模型是核心语言的一部分

- std::thread 是标准库的一部分


由于以上的原因，C++标准组织决定为语言添加内存模型，他们参照了 Java。由于 Java 在上世纪 90 年代就定义了内存模型，令人惊奇的是它在 Java 第一个官方发布的版本中就存在了。这使 Java 成为以一个定义并支持内存模型的广泛使用的语言。 Java 内存模型的目的是确保多线程安全地执行和访问内存。在 Java 中，不可信代码和可信代码运行于相同的虚拟机并共享内存。语言必须保证不受信任的线程不会违反类型安全或具有会损害另一个线程完整性的操作。

工作组也参考了 POSIX 标准的 pthread 库。因为它是当时最官方使用的线程库。pthread 实现假设开发者从不产生竞争。根据 POSIX 规定，如果开发者导致数据竞争，程序将无效。但是 pthread 并没有定义内存模型。

工作组决定将 Java 内存模型的 2006 版作为 C++ 内存模型的一部分。但是其也有不足之处，C++ 并没有类型安全，保证每一个内存访问的顺序一致性的成本与 C++ 核心语言高性能的哲学不相容。例如：

对于某些数据类型，Java 内存模型要求对内存中任何位置的任何变量的每次读取都必须以原子方式完成。大多数平台需要额外的CPU指令，在内存总线上增加额外的开销，以确保遵守内存模型。这种成本对于大多数 C++ 开发者将是不可接受的。Java 运行时必须确保当从内存中读取指针值时，它所指向的所有内存都已完全写入并同步。因此，每次用Java构造对象时，都需要额外的指令和内存操作以保证内存模型。这会对c++对象实例化产生重大影响。

因此决定不使用 Java 内存模型，而是重新创建一个内存模型。它融合了 Java 的思想和在 posix 中使用关键线程的经验。有信息证实他们知道这种方法存在风险，但他们相信这是正确的选择。


在 2006 年，一个主要关心的问题是：像 pthread 一样的线程库如果没有程序员、编译器和线程库的合作，pthread 不能保证有效。没有办法保证程序员的初衷在运行时得到遵守。这就是内存模型定义的内容。

**内存模型在 C++ 语言中并不可见，而是由编译器实现者遵守**。因此所有的多线程应用即使被优化和重排序也能正确的访问共享内存。

![C++并发时间线](images/concurrency_timeline.png)

![C++并发时间线](images/concurrency_timeline2.png)

[参考](https://www.youtube.com/watch?v=KgzjxfYaScU&t=6s)
https://en.cppreference.com/w/cpp/language/memory_model


### C++ 内存模型包括





## 线程安全的三个条件

volatile

- 可见性：

可见性是一种复杂的属性，因为可见性中的错误总是会违背我们的直觉。通常，我们无法确保执行读操作的线程能适时地看到其他线程写入的值，有时甚至是根本不可能的事情。为了确保多个线程之间对内存写入操作的可见性，必须使用同步机制。

可见性，是指线程之间的可见性，一个线程修改的状态对另一个线程是可见的。也就是一个线程修改的结果。另一个线程马上就能看到。比如：用volatile 修饰的变量，就会具有可见性。当把变量声明为volatile类型后，编译器与运行时都会注意到这个变量是共享的，因此不会将该变量上的操作与其他内存操作一起重排序。volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，因此在读取volatile类型的变量时总会返回最新写入的值。，即直接修改内存。所以对其他线程是可见的。但是这里需要注意一个问题，volatile只能让被他修饰内容具有可见性，但不能保证它具有原子性。比如 volatile int a = 0；之后有一个操作 a++；这个变量a具有可见性，但是a++ 依然是一个非原子操作，也就是这个操作同样存在线程安全问题。

volatile变量的内存可见性是基于内存屏障(Memory Barrier)实现的，什么是内存屏障?内存屏障，又称内存栅栏，是一个CPU指令。在程序运行时，为了提高执行性能，编译器和处理器会对指令进行重排序，通过插入特定类型的内存屏障来禁止特定类型的编译器重排序和处理器重排序，插入一条内存屏障会告诉编译器和CPU：不管什么指令都不能和这条Memory Barrier指令重排序。

https://www.jianshu.com/p/08a0a8c984ab

在 Java 中 volatile、synchronized 和 final 实现可见性。

- 原子性：

即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。比如 a=0；（a非long和double类型） 这个操作是不可分割的，那么我们说这个操作时原子操作。再比如：a++； 这个操作实际是a = a + 1；是可分割的，所以他不是一个原子操作。非原子操作都会存在线程安全问题，需要我们使用同步技术（sychronized）来让它变成一个原子操作。一个操作是原子操作，那么我们称它具有原子性。java的concurrent包下提供了一些原子类，我们可以通过阅读API来了解这些原子类的用法。比如：AtomicInteger、AtomicLong、AtomicReference等。

虽然原子性在单核处理器上能够保证线程安全，但是在多核处理器上，程序执行是并行的，因此还是需要考虑其他特性，例如互斥。

在 Java 中 synchronized 和在 lock、unlock 中操作保证原子性。

- 有序性：

Java 语言提供了 volatile 和 synchronized 两个关键字来保证线程之间操作的有序性，volatile 是因为其本身包含“禁止指令重排序”的语义，synchronized 是由“一个变量在同一个时刻只允许一条线程对其进行 lock 操作”这条规则获得的，此规则决定了持有同一个对象锁的两个同步块只能串行执行。


> 当一个变量定义为 volatile 之后，将具备两种特性：

1.保证此变量对所有的线程的可见性，这里的“可见性”，当一个线程修改了这个变量的值，volatile 保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。但普通变量做不到这点，普通变量的值在线程间传递均需要通过主内存（详见：Java内存模型）来完成。

2.禁止指令重排序优化。有volatile修饰的变量，赋值后多执行了一个“load addl $0x0, (%esp)”操作，这个操作相当于一个内存屏障（指令重排序时不能把后面的指令重排序到内存屏障之前的位置），只有一个CPU访问内存时，并不需要内存屏障；（什么是指令重排序：是指CPU采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理）。

volatile 性能：
volatile 的读性能消耗与普通变量几乎相同，但是写操作稍慢，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。

volatile 的可见性并不是缓存一致性，而是缓存锁或者总线锁。

> synchronized 后，仍需要加 volatile

synchronized 既保证了原子性又保证了可见性。


## 如何从代码预测一个操作是不是原子性的？
要判断原子性需要明确：程序存储的地方在内存，而计算需要使用寄存器。以下操作是原子性的：

- 从内存加载数据到寄存器（同时要判断位宽，超出位宽的操作不是原子的，例如在 32 位机上加载 64 位数据）
- 寄存器之间直接运算
- 将寄存器数据保存到内存。

我们的程序逻辑经常遇到这样的操作序列：

1、读一个位于memory中的变量的值到寄存器中

2、修改该变量的值（也就是修改寄存器中的值）

3、将寄存器中的数值写回memory中的变量值

例如：

a=32 是一个原子操作,

### 原子操作

C/C++11 定义了原子类型 `atomic_<type>`，例如 `atomic_bool`, `atomic_char`, `atomic_int`...。
C 定义在 `stdatomic.h` 中，使用 `_Atomic()` 宏定义。
C++ 定义在 `atomic` 中，使用 `atomic<type>` 模板定义。

std::atomic<> wraps operations that, in pre-C++ 11 times, had to be performed using (for example) interlocked functions with MSVC or atomic bultins in case of GCC.



编译器将保证这些操作都是原子性的，也就是说，确保任意时刻只有一个线程对这个资源进行访问，编译器将保证，多个线程访问这个共享资源的正确性。

C/C++ 的原子操作，都是使用编译器中的内置函数实现的，具体的代码没有找到。gcc 提供了如下的内置函数。

https://gcc.gnu.org/onlinedocs/gcc/_005f_005fatomic-Builtins.html

[以及 __sync_ 前缀的历史遗留接口](https://gcc.gnu.org/onlinedocs/gcc/_005f_005fsync-Builtins.html)

根据编译目标平台和编译参数的不同，会生成不同的代码。





#### 内核原子操作

由于内核无法使用用户 API，在内核中，也定义了一套原子操作 API，

#### 实现机制
X86 处理器

Cacheline Lock
为了实现多核Cache一致性，现在的硬件基本采用MESI协议（或者MESI变种）维护一致性。因此我们可以借助多核Cache一致性协议MESI实现原子操作。我们知道Cache line的状态处于Exclusive或者Modified时，可以说明该变量只有当前CPU私有Cache缓存了该数据。所以我们可以直接修改Cache line即可更新数据。并且MESI协议可以帮我们保证互斥。当然这不能不能保证RMW操作期间不被打断，因此我们还需要做些手脚实现原子操作。

我们依然假设只有2个CPU的系统。当CPU0试图执行原子递增操作时。a) CPU0发出"Read Invalidate"消息，其他CPU将原子变量所在的缓存无效，并从Cache返回数据。CPU0将Cache line置成Exclusive状态。然后将该cache line标记locked。b) 然后CPU0读取原子变量，修改，最后写入cache line。c) 将cache line置位unlocked。

在步骤a)和c)之间，如果其他CPU（例如CPU1）尝试执行一个原子递增操作，CPU1会发送一个"Read Invalidate"消息，CPU0收到消息后，检查对应的cache line的状态是locked，暂时不回复消息（CPU1会一直等待CPU0回复Invalidate Acknowledge消息）。直到cache line变成unlocked。这样就可以实现原子操作。我们称这种方式为锁cache line。这种实现方式必须要求操作的变量位于一个cache line。


## 可重入

可重入是指已经获取锁的进程可以在内部调用另一个要获取同一把锁的代码。


```Java
class T {
    void synchronized a {
        b();
    }

    void synchronized b {

    }
}
```

a 和 b 要获取同一把锁，在同一个线程中 a 可以调用 b。 这是必须的。因为如果不允许可重入锁。继承的 synchronized 调用 super 将会导致死锁。

```Java
class T {
    protect void synchronized a {
        //...
    }
}

class V extends T {
    protect void synchronized a {
        super.a();
    }
}
```

如果不允许可重入，A.a 在调用 super.a() 时，因为获取不到锁，而产生死锁。因为此时都要获取 V 的对象。

## 获取锁程序产生异常，会释放锁。

如果不想释放锁，可以 catch 处理。

## 切线程的本质

只有操作系统才能真正切线程，客户端切线程不过是将一个任务放到线程的执行队列中，等待执行。由于线程可能被 wait 等处于等待阻塞状态，因此一般需要唤醒线程。


# 线程问题

https://mp.weixin.qq.com/s/oLz_F7zhUN6-b-KaI8CMRw


## 内存模型

内存模型主要关注于多线程对内存的访问 https://stackoverflow.com/questions/6319146/c11-introduced-a-standardized-memory-model-what-does-it-mean-and-how-is-it-g


参考：

[TLS 代码分析](https://blog.csdn.net/yeholmes/article/details/106179650)
[Create TLS](https://www.cnblogs.com/xiaohaigegede/p/16602888.html)